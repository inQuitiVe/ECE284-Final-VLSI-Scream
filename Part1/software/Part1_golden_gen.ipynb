{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radical-fifty",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "\n",
    "##################################### Modify here ########################################\n",
    "model_name = \"VGG16_vanilla\"\n",
    "model = VGG16_vanilla()\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "model.to(\"cuda\")\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a020aef9-1210-47e4-9950-cd1b023a4e08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 8986/10000 (90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = f\"result/{model_name}/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceramic-nigeria",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantConv2d(\n",
      "  8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ")\n",
      "ReLU(inplace=True)\n",
      "torch.Size([128, 8, 4, 4])\n",
      "torch.Size([128, 8, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "\n",
    "model.features[27].register_forward_pre_hook(save_output)\n",
    "model.features[28].register_forward_pre_hook(save_output)\n",
    "model.features[29].register_forward_pre_hook(save_output)\n",
    "print(model.features[27])\n",
    "print(model.features[28])\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "out = model(images)\n",
    "\n",
    "act_grabbed_batch  = save_output.outputs[0][0]\n",
    "psum_grabbed_batch = save_output.outputs[1][0]\n",
    "relu_grabbed_batch = save_output.outputs[2][0]\n",
    "conv_grabbed = model.features[27]\n",
    "\n",
    "\n",
    "\n",
    "print(act_grabbed_batch.size())\n",
    "print(psum_grabbed_batch.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1369846c-93f1-44a6-98b1-58b625b09e4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.999999523162842, -6.0, -4.999999523162842, -4.0, -3.0, -2.0, -1.0, -0.0, 1.0, 2.0, 3.0, 4.0, 4.999999523162842, 6.0, 6.999999523162842]\n"
     ]
    }
   ],
   "source": [
    "weight_q = conv_grabbed.weight_q\n",
    "w_alpha = conv_grabbed.weight_quant.wgt_alpha\n",
    "w_bit = 4\n",
    "\n",
    "weight_int = weight_q / (w_alpha / (2**(w_bit-1)-1))\n",
    "\n",
    "\n",
    "print(sorted(set(weight_int.detach().cpu().numpy().flatten().tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "interior-oxygen",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 2.0, 3.000000238418579, 4.0, 5.0, 6.000000476837158, 7.0, 8.0, 9.0, 10.0, 10.999999046325684, 12.000000953674316, 13.000000953674316, 14.0, 14.999999046325684]\n"
     ]
    }
   ],
   "source": [
    "act = act_grabbed_batch\n",
    "act_alpha  = conv_grabbed.act_alpha\n",
    "act_bit = 4\n",
    "act_quant_fn = act_quantization(act_bit)\n",
    "\n",
    "act_q = act_quant_fn(act, act_alpha)\n",
    "\n",
    "act_int = act_q / (act_alpha / (2**act_bit-1))\n",
    "print(sorted(set(act_int.detach().cpu().numpy().flatten().tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "victorian-above",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_int = torch.nn.Conv2d(in_channels = 8, out_channels=8, kernel_size = 3, padding=1)\n",
    "conv_int.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "conv_int.bias = conv_grabbed.bias\n",
    "output_int = conv_int(act_int)\n",
    "output_recovered = output_int * (act_alpha / (2**act_bit-1)) * (w_alpha / (2**(w_bit-1)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "designed-auction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_ref = torch.nn.Conv2d(in_channels = 8, out_channels=8, kernel_size = 3, padding=1)\n",
    "conv_ref.weight = conv_grabbed.weight_q\n",
    "conv_ref.bias = conv_grabbed.bias\n",
    "output_ref = conv_ref(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83f5049a-3885-4dc4-bb69-0f7d112edbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# act_int.size = torch.Size([128, 64, 32, 32])  <- batch_size, input_ch, ni, nj\n",
    "a_int = act_int[0,:,:,:]  # pick only one input out of batch\n",
    "# a_int.size() = [64, 32, 32]\n",
    "\n",
    "# conv_int.weight.size() = torch.Size([64, 64, 3, 3])  <- output_ch, input_ch, ki, kj\n",
    "w_int = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1))  # merge ki, kj index to kij\n",
    "# w_int.weight.size() = torch.Size([64, 64, 9])\n",
    "                      \n",
    "padding = 1\n",
    "stride = 1\n",
    "array_size = 8 # row and column number\n",
    "\n",
    "nig = range(a_int.size(1))  ## ni group\n",
    "njg = range(a_int.size(2))  ## nj group\n",
    "\n",
    "icg = range(int(w_int.size(1)))  ## input channel \n",
    "ocg = range(int(w_int.size(0)))  ## output channel\n",
    "\n",
    "ic_tileg = range(int(len(icg)/array_size))\n",
    "oc_tileg = range(int(len(ocg)/array_size))\n",
    "\n",
    "kijg = range(w_int.size(2))\n",
    "ki_dim = int(math.sqrt(w_int.size(2)))  ## Kernel's 1 dim size\n",
    "\n",
    "######## Padding before Convolution #######\n",
    "a_pad = torch.zeros(len(icg), len(nig)+padding*2, len(nig)+padding*2).cuda()\n",
    "# a_pad.size() = [64, 32+2pad, 32+2pad]\n",
    "a_pad[ :, padding:padding+len(nig), padding:padding+len(njg)] = a_int.cuda()\n",
    "a_pad = torch.reshape(a_pad, (a_pad.size(0), -1))\n",
    "# a_pad.size() = [64, (32+2pad)*(32+2pad)]\n",
    "\n",
    "\n",
    "a_tile = torch.zeros(len(ic_tileg), array_size,    a_pad.size(1)).cuda() \n",
    "w_tile = torch.zeros(len(oc_tileg)*len(ic_tileg), array_size, array_size, len(kijg)).cuda() \n",
    "\n",
    "for ic_tile in ic_tileg:\n",
    "    a_tile[ic_tile,:,:] = a_pad[ic_tile*array_size:(ic_tile+1)*array_size,:]\n",
    "\n",
    "for ic_tile in ic_tileg:\n",
    "    for oc_tile in oc_tileg:\n",
    "        w_tile[oc_tile*len(oc_tileg) + ic_tile,:,:,:] = w_int[oc_tile*array_size:(oc_tile+1)*array_size, ic_tile*array_size:(ic_tile+1)*array_size, :]\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "\n",
    "p_nijg = range(a_pad.size(1)) ## psum nij group\n",
    "\n",
    "psum = torch.zeros(len(ic_tileg), len(oc_tileg), array_size, len(p_nijg), len(kijg)).cuda() \n",
    "\n",
    "for kij in kijg:\n",
    "    for ic_tile in ic_tileg:       # Tiling into array_sizeXarray_size array\n",
    "        for oc_tile in oc_tileg:   # Tiling into array_sizeXarray_size array        \n",
    "            for nij in p_nijg:       # time domain, sequentially given input\n",
    "                    m = nn.Linear(array_size, array_size, bias=False)\n",
    "                    #m.weight = torch.nn.Parameter(w_int[oc_tile*array_size:(oc_tile+1)*array_size, ic_tile*array_size:(ic_tile+1)*array_size, kij])\n",
    "                    m.weight = torch.nn.Parameter(w_tile[len(oc_tileg)*oc_tile+ic_tile,:,:,kij])\n",
    "                    psum[ic_tile, oc_tile, :, nij, kij] = m(a_tile[ic_tile,:,nij]).cuda()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91989557-ba13-499a-938f-711844faa0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "a_pad_ni_dim = int(math.sqrt(a_pad.size(1))) # 32\n",
    "\n",
    "o_ni_dim = int((a_pad_ni_dim - (ki_dim- 1) - 1)/stride + 1)\n",
    "o_nijg = range(o_ni_dim**2)    \n",
    "    \n",
    "out = torch.zeros(len(ocg), len(o_nijg)).cuda()\n",
    "oc_tile_idx_l, oc_tile_idx_r = 0, 0\n",
    "  \n",
    "### SFP accumulation ###\n",
    "for o_nij in o_nijg: \n",
    "    for kij in kijg:\n",
    "        for ic_tile in ic_tileg:    \n",
    "            for oc_tile in oc_tileg:   \n",
    "                # select the indices range to accumulate, 0:16, 16:32, 32:48, 48:64\n",
    "                oc_tile_idx_l, oc_tile_idx_r = oc_tile*array_size, (oc_tile+1)*array_size\n",
    "                # different input channels are summed up here\n",
    "                out[oc_tile_idx_l:oc_tile_idx_r, o_nij] = out[oc_tile_idx_l:oc_tile_idx_r, o_nij] + \\\n",
    "                psum[ic_tile, oc_tile, :, int(o_nij/o_ni_dim)*a_pad_ni_dim + o_nij%o_ni_dim + int(kij/ki_dim)*a_pad_ni_dim + kij%ki_dim, kij]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ab10dcc-da17-478a-91c8-a0d383963dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0002, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_2D = torch.reshape(out, (out.size(0), o_ni_dim, -1))\n",
    "difference = (out_2D - output_int[0,:,:,:])\n",
    "print(difference.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6699de19-5b6c-46d0-b578-cdab23e298b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_tile.size():  torch.Size([1, 8, 36])\n",
      "a_tile[0].size():  torch.Size([8, 36])\n"
     ]
    }
   ],
   "source": [
    "### show this cell partially. The following cells should be printed by students ###\n",
    "tile_id = 0 \n",
    "X = a_tile[tile_id]  # [tile_num, array row num, time_steps]\n",
    "print(\"a_tile.size(): \", a_tile.size())\n",
    "print(\"a_tile[0].size(): \", X.size())\n",
    "\n",
    "bit_precision = 4\n",
    "file = open(f'golden/Part1/activation_tile{tile_id}.txt', 'w') #write to file\n",
    "file.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n",
    "file.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(X.size(1)):  # time step\n",
    "    for j in range(X.size(0)): # row #\n",
    "        X_bin = '{0:04b}'.format(round(X[7-j,i].item()))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(X_bin[k])        \n",
    "        # file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file    \n",
    "\n",
    "\n",
    "\n",
    "file = open(f'golden/Part1/viz/viz_activation_tile{tile_id}.txt', 'w') #write to file\n",
    "file.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n",
    "file.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(X.size(1)):  # time step\n",
    "    for j in range(X.size(0)): # row #\n",
    "        X_bin = '{0:04b}'.format(round(X[7-j,i].item()))\n",
    "\n",
    "        file.write(f'{round(X[7-j,i].item()): 3d}')\n",
    "\n",
    "        file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "682ea911-2a0b-4b26-8f42-53fc005769d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Complete this cell ###\n",
    "\n",
    "for kij in kijg:\n",
    "    tile_id = 0 \n",
    "    W = w_tile[tile_id,:,:,kij]  # w_tile[tile_num, array col num, array row num, kij]\n",
    "    \n",
    "    bit_precision = 4\n",
    "    file = open(f'golden/Part1/weight_itile0_otile0_kij{kij}.txt', 'w') #write to file\n",
    "    file.write('#col0row7[msb-lsb],col0row6[msb-lst],....,col0row0[msb-lst]#\\n')\n",
    "    file.write('#col1row7[msb-lsb],col1row6[msb-lst],....,col1row0[msb-lst]#\\n')\n",
    "    file.write('#................#\\n')\n",
    "    \n",
    "    \n",
    "    for i in range(W.size(0)):  # array col num\n",
    "        for j in range(W.size(1)): # array row num\n",
    "            # 2's complement\n",
    "            W_signed = round(W[i, 7-j].item())\n",
    "            if W_signed < 0:\n",
    "                W_signed += 16\n",
    "            \n",
    "            W_bin = '{0:04b}'.format(W_signed)\n",
    "            for k in range(bit_precision):\n",
    "                file.write(W_bin[k])        \n",
    "            # file.write(' ')  # for visibility with blank between words, you can use\n",
    "        file.write('\\n')\n",
    "    file.close() #close file    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    file = open(f'golden/Part1/viz/viz_weight_itile0_otile0_kij{kij}.txt', 'w') #write to file\n",
    "    file.write('#col0row7[msb-lsb],col0row6[msb-lst],....,col0row0[msb-lst]#\\n')\n",
    "    file.write('#col1row7[msb-lsb],col1row6[msb-lst],....,col1row0[msb-lst]#\\n')\n",
    "    file.write('#................#\\n')\n",
    "    \n",
    "    for i in range(W.size(0)):  # array col num\n",
    "        for j in range(W.size(1)): # array row num\n",
    "            # 2's complement\n",
    "            W_signed = round(W[i, 7-j].item())\n",
    "            W_signed = f'{W_signed: 3d}'    \n",
    "            file.write(W_signed) \n",
    "            file.write(' ')  # for visibility with blank between words, you can use\n",
    "        file.write('\\n')\n",
    "    file.close() #close file   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf614897-aff7-46ad-a704-e546e6fc2cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16])\n"
     ]
    }
   ],
   "source": [
    "## save out\n",
    "# Comment these 2 lines out if you're dealing with conv's output directly. \n",
    "# \n",
    "print(out.size())\n",
    "bit_precision = 16\n",
    "\n",
    "file = open('golden/Part1/out_raw.txt', 'w') #write to file\n",
    "file.write('#time0co7[msb-lsb],time0co6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "file.write('#time1co7[msb-lsb],time1co6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(out.size(1)):  # time step\n",
    "    for j in range(out.size(0)): # array col\n",
    "        # 2's complement\n",
    "        out_signed = round(out[7-j, i].item())\n",
    "        if out_signed < 0:\n",
    "            out_signed += 65536\n",
    "        \n",
    "        out_bin = '{0:016b}'.format(out_signed)\n",
    "        for k in range(bit_precision):\n",
    "            file.write(out_bin[k])        \n",
    "        # file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file    \n",
    "\n",
    "\n",
    "file = open('golden/Part1/viz/viz_out_raw.txt', 'w') #write to file\n",
    "file.write('#time0co7[msb-lsb],time0co6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "file.write('#time1co7[msb-lsb],time1co6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(out.size(1)):  # time step\n",
    "    for j in range(out.size(0)): # array col\n",
    "        out_signed = round(out[7-j, i].item())\n",
    "        out_signed = f'{out_signed: 6d}'\n",
    "        file.write(out_signed)        \n",
    "        file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b4a661a-0f6d-4c14-a17d-3368f8c1cbdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16])\n"
     ]
    }
   ],
   "source": [
    "## save out\n",
    "# Comment these 2 lines out if you're dealing with conv's output directly. \n",
    "# \n",
    "print(out.size())\n",
    "bit_precision = 16\n",
    "\n",
    "file = open('golden/Part1/out.txt', 'w') #write to file\n",
    "file.write('#time0co7[msb-lsb],time0co6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "file.write('#time1co7[msb-lsb],time1co6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(out.size(1)):  # time step\n",
    "    for j in range(out.size(0)): # array col\n",
    "        # 2's complement\n",
    "        out_signed = round(out[7-j, i].item())\n",
    "        if out_signed < 0:\n",
    "            out_signed = 0\n",
    "        \n",
    "        out_bin = '{0:016b}'.format(out_signed)\n",
    "        for k in range(bit_precision):\n",
    "            file.write(out_bin[k])        \n",
    "        # file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file    \n",
    "\n",
    "\n",
    "file = open('golden/Part1/viz/viz_out.txt', 'w') #write to file\n",
    "file.write('#time0co7[msb-lsb],time0co6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "file.write('#time1co7[msb-lsb],time1co6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(out.size(1)):  # time step\n",
    "    for j in range(out.size(0)): # array col\n",
    "        out_signed = round(out[7-j, i].item())\n",
    "        if out_signed < 0:\n",
    "            out_signed = 0\n",
    "        out_signed = f'{out_signed: 6d}'\n",
    "        file.write(out_signed)        \n",
    "        file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d44b59-6cb5-4b74-8b66-29ff2e0cdae9",
   "metadata": {},
   "source": [
    "# Stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba7714e3-e435-46b4-9b7e-cf88bbec2d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Complete this cell ###\n",
    "ic_tile_id = 0 \n",
    "oc_tile_id = 0 \n",
    "\n",
    "\n",
    "kij = 0\n",
    "psum_tile = psum[ic_tile_id,oc_tile_id,:,:,kij]  \n",
    "# psum_tile.shape(): array col num , p_nijg(time step)\n",
    "\n",
    "relu_grabbed\n",
    "\n",
    "\n",
    "\n",
    "bit_precision = 16\n",
    "file = open('psum.txt', 'w') #write to file\n",
    "file.write('#time0co7[msb-lsb],time0co6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "file.write('#time1co7[msb-lsb],time1co6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "\n",
    "\n",
    "for i in range(psum_tile.size(1)):  # time step\n",
    "    for j in range(psum_tile.size(0)): # col #\n",
    "\n",
    "        # 2's complement\n",
    "        psum_tile_signed = round(psum_tile[7-j,i].item())\n",
    "        if psum_tile_signed < 0:\n",
    "            psum_tile_signed += 65536\n",
    "    \n",
    "        psum_tile_bin = '{0:016b}'.format(psum_tile_signed)\n",
    "        \n",
    "        for k in range(bit_precision):\n",
    "            file.write(psum_tile_bin[k])        \n",
    "        # file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6cba3182-bd93-4ef0-8b04-d7b408473339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference: 0.0\n",
      "Tiled output calculation matches the original one!\n"
     ]
    }
   ],
   "source": [
    "out_tile_cal_2D = torch.reshape(out, (out.size(0), o_ni_dim, -1)) # nij -> ni & nj\n",
    "\n",
    "difference = (out_2D - out_tile_cal_2D)\n",
    "\n",
    "if difference.abs().sum() == 0.0:\n",
    "    print(f\"Difference: {difference.abs().sum()}\")\n",
    "    print(\"Tiled output calculation matches the original one!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c03eab-707c-44c0-a9fa-b8ae582e0a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
